{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae01923-eeb2-4bae-8462-4b6219771eaf",
   "metadata": {},
   "source": [
    "# GI67216 Jainam Maheshkumar Patel\n",
    "# week 7 Homework \n",
    "\n",
    "\n",
    "##### Study Reference: NLTK book, class notes and geeks for geeks...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f21e8bc-5150-44d8-9975-13827f0115d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: nltk in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: click in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: pandas in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (2.0.3)\n",
      "Requirement already satisfied: pyfume in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (0.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3)\n",
      "Requirement already satisfied: simpful in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.12.0)\n",
      "Requirement already satisfied: fst-pso in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim nltk scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "275f48cc-4982-4a34-b32e-5944f4feb487",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/jainampatel/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968e2d5-d128-4e39-8bcf-0c28b8887c77",
   "metadata": {},
   "source": [
    "## Using Gensim, train a doc2vec model on the Brown Corpus. Try to classify documents from each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a429c393-1469-4aec-a3c9-0d9936ad199a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY of the code : 38.82%\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.corpus import brown\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# here i load the Brown Corpus.....\n",
    "brown_c = brown.sents(categories=brown.categories())\n",
    "\n",
    "\n",
    "# here i tagged each sentence with its category...\n",
    "tag_d = [TaggedDocument(words=sent, tags=[category]) for category, sentences in zip(brown.categories(), brown_c) for sent in sentences]\n",
    "\n",
    "\n",
    "\n",
    "# here is the spliting of the data into training and testing sets....\n",
    "train_data, test_data = train_test_split(tag_d, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# here i train a Doc2Vec model....\n",
    "model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "model.build_vocab(train_data)\n",
    "model.train(train_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "\n",
    "\n",
    "# here i filtered out tags not present in the vocabulary....\n",
    "train_data = [tag for tag in train_data if tag.tags[0] in model.dv.index_to_key]\n",
    "test_data = [tag for tag in test_data if tag.tags[0] in model.dv.index_to_key]\n",
    "\n",
    "\n",
    "\n",
    "# here i tried to extract document vectors for training and testing sets.....\n",
    "train_v = [model.dv[tag.tags[0]] for tag in train_data]\n",
    "test_v = [model.dv[tag.tags[0]] for tag in test_data]\n",
    "\n",
    "\n",
    "\n",
    "# at the end i train a classifier (Logistic Regression in this case)......\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_v, [tag.tags[0] for tag in train_data])\n",
    "\n",
    "\n",
    "\n",
    "# and made predictions on the test set.....\n",
    "predictions = classifier.predict(test_v)\n",
    "\n",
    "\n",
    "acc = accuracy_score([tag.tags[0] for tag in test_data], predictions)\n",
    "print(f\"ACCURACY of the code : {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f1688-d2ec-48ca-8e1b-e9c2307e23ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b29d6c7-80af-43b0-acc5-f5b0560253b2",
   "metadata": {},
   "source": [
    "## Use the stop word removal code from earlier on the 20 user groups:\n",
    "#### - How does that effect the word model distance of documents?\n",
    "#### - How does it effect the logistic regression classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60fc6d31-5c22-4a4a-8b54-c79f66582cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for this code : 33.33%\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.corpus import brown\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "# i followed same steps as above questions in this one too.....\n",
    "stop_w = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "\n",
    "brown_c = brown.sents(categories=brown.categories())\n",
    "\n",
    "\n",
    "\n",
    "# here i tried to preprocess data: remove stop words and punctuation......\n",
    "def preprocess_d(sentences):\n",
    "    preprocessed_s = []\n",
    "    for sent in sentences:\n",
    "        sent = [word.lower() for word in sent if word.lower() not in stop_w and word.lower() not in punctuation]\n",
    "        preprocessed_s.append(sent)\n",
    "    return preprocessed_s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# here i apply stop word removal....\n",
    "preprocessed_corp = preprocess_d(brown_c)\n",
    "\n",
    "\n",
    "\n",
    "tag_d = [TaggedDocument(words=sent, tags=[category]) for category, sentences in zip(brown.categories(), preprocessed_corp) for sent in sentences]\n",
    "\n",
    "\n",
    "\n",
    "train_data, test_data = train_test_split(tag_d, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "model.build_vocab(train_data)\n",
    "model.train(train_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "\n",
    "\n",
    "train_data = [tag for tag in train_data if tag.tags[0] in model.dv.index_to_key]\n",
    "test_data = [tag for tag in test_data if tag.tags[0] in model.dv.index_to_key]\n",
    "\n",
    "\n",
    "\n",
    "train_v = [model.dv[tag.tags[0]] for tag in train_data]\n",
    "test_v = [model.dv[tag.tags[0]] for tag in test_data]\n",
    "\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_vectors, [tag.tags[0] for tag in train_data])\n",
    "\n",
    "\n",
    "\n",
    "predictions = classifier.predict(test_v)\n",
    "\n",
    "\n",
    "\n",
    "acc = accuracy_score([tag.tags[0] for tag in test_data], predictions)\n",
    "print(f\"ACCURACY for this code : {acc * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe2f4e0-d1d5-4a30-8dba-3102f8cf3759",
   "metadata": {},
   "source": [
    "**Now here is the analysation on the effects of stop word removal:**\n",
    "\n",
    "- Word Model Distance of Documents: Removing stop words may reduces the number of unique words in each document, leading to a decrease in the overall dimensionality of the document vectors. so this all often results in a more focused and meaningful representation of the document content.\n",
    "\n",
    "- Effect on Logistic Regression Classifier: Removing stop words can help the logistic regression classifier to generalize better by focusing on more meaningful words. mostly stop words are often common across different categories and may not contribute much to the discriminative power of the classifier.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638f43e-fb8f-4558-89d0-a6fd12732a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
